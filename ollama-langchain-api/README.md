# ğŸš€ Ollama + LangChain API

Uma API moderna que demonstra como turbinar modelos de IA locais usando LangChain para criar aplicaÃ§Ãµes mais inteligentes e contextuais.

## âœ¨ Funcionalidades

### ğŸ¤– Chat com IA
- **Chat Simples**: Conversas diretas com modelos Ollama
- **Chat com Contexto**: Adicione contexto adicional para respostas mais precisas
- **Chat com MemÃ³ria**: Mantenha conversas com histÃ³rico entre sessÃµes

### ğŸ”— LangChain Chains
- **Q&A Chain**: Perguntas e respostas estruturadas
- **Summarize Chain**: Resumo de textos longos
- **Translate Chain**: TraduÃ§Ã£o entre idiomas

### ğŸ› ï¸ UtilitÃ¡rios
- **Health Check**: Monitoramento do status da API e Ollama
- **Listagem de Modelos**: Veja todos os modelos disponÃ­veis

## ğŸ¨ Frontend Moderno

A API agora inclui um **frontend moderno e responsivo** com:

- ğŸ¨ **Design Dark Theme** - Perfeito para seus olhos
- ğŸ“± **Interface Responsiva** - Funciona em desktop e mobile
- âš¡ **NavegaÃ§Ã£o por Abas** - OrganizaÃ§Ã£o intuitiva das funcionalidades
- ğŸ”„ **Chat em Tempo Real** - Interface de chat moderna
- ğŸ›ï¸ **Controles de Temperatura** - Ajuste a criatividade das respostas
- ğŸ”” **NotificaÃ§Ãµes Toast** - Feedback visual para o usuÃ¡rio
- ğŸ“Š **Indicador de Status** - Monitore se a API estÃ¡ online
- â³ **Loading States** - Indicadores visuais durante processamento

### Como Acessar o Frontend

1. **Inicie a API**:
   ```bash
   uvicorn app.main:app --reload --host 127.0.0.1 --port 8000
   ```

2. **Acesse no navegador**:
   ```
   http://127.0.0.1:8000
   ```

3. **Explore as funcionalidades**:
   - Use as abas no menu lateral para navegar
   - Teste o chat simples primeiro
   - Experimente as diferentes chains
   - Verifique o status da API

## ğŸ› ï¸ Tecnologias

### Backend
- **FastAPI**: Framework web moderno e rÃ¡pido
- **Ollama**: Para rodar modelos de IA localmente
- **LangChain**: Framework para aplicaÃ§Ãµes de IA
- **Pydantic**: ValidaÃ§Ã£o e serializaÃ§Ã£o de dados

### Frontend
- **HTML5**: Estrutura semÃ¢ntica
- **CSS3**: Design moderno com CSS Grid e Flexbox
- **JavaScript ES6+**: Funcionalidade interativa
- **Font Awesome**: Ãcones modernos
- **Google Fonts**: Tipografia elegante

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Python 3.8+
- Ollama instalado
- Modelo de IA baixado (ex: `llama2`)

### 1. Instalar DependÃªncias
```bash
pip install -r requirements.txt
```

### 2. Configurar VariÃ¡veis de Ambiente
```bash
cp env.example .env
# Edite o arquivo .env conforme necessÃ¡rio
```

### 3. Baixar Modelo Ollama
```bash
ollama pull llama2
```

### 4. Executar a API
```bash
uvicorn app.main:app --reload --host 127.0.0.1 --port 8000
```

### 5. Acessar a AplicaÃ§Ã£o
- **Frontend**: http://127.0.0.1:8000
- **DocumentaÃ§Ã£o API**: http://127.0.0.1:8000/docs
- **Health Check**: http://127.0.0.1:8000/health

## ğŸ“¡ Endpoints da API

### Chat
- `POST /chat` - Chat simples
- `POST /chat/context` - Chat com contexto
- `POST /chat/memory` - Chat com memÃ³ria

### LangChain Chains
- `POST /chat/chain` - Usar chains especÃ­ficas (qa, summarize, translate)

### UtilitÃ¡rios
- `GET /health` - Health check
- `GET /chat/models` - Listar modelos disponÃ­veis

## ğŸ¯ Exemplos de Uso

### Chat Simples
```bash
curl -X POST "http://127.0.0.1:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "OlÃ¡! Como vocÃª estÃ¡?", "temperature": 0.7}'
```

### Chat com Contexto
```bash
curl -X POST "http://127.0.0.1:8000/chat/context" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Explique este conceito",
    "context": "Estamos falando sobre inteligÃªncia artificial",
    "temperature": 0.7
  }'
```

### Usar LangChain Chain
```bash
curl -X POST "http://127.0.0.1:8000/chat/chain" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Texto para resumir...",
    "chain_type": "summarize"
  }'
```

## ğŸ³ Docker (Opcional)

### Executar com Docker Compose
```bash
docker-compose up -d
```

### Executar apenas a API
```bash
docker build -t ollama-langchain-api .
docker run -p 8000:8000 ollama-langchain-api
```

## ğŸ“ Estrutura do Projeto

```
ollama-langchain-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # AplicaÃ§Ã£o principal
â”‚   â”œâ”€â”€ models.py            # Modelos Pydantic
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ chat.py          # Rotas de chat
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ ollama_service.py # ServiÃ§o Ollama
â”œâ”€â”€ static/                  # Frontend
â”‚   â”œâ”€â”€ index.html          # PÃ¡gina principal
â”‚   â”œâ”€â”€ styles.css          # Estilos CSS
â”‚   â””â”€â”€ script.js           # JavaScript
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ env.example             # Exemplo de configuraÃ§Ã£o
â”œâ”€â”€ docker-compose.yml      # ConfiguraÃ§Ã£o Docker
â”œâ”€â”€ Dockerfile              # Imagem Docker
â””â”€â”€ README.md               # Este arquivo
```

## ğŸ¨ CaracterÃ­sticas do Frontend

### Design System
- **Tema Escuro**: Cores suaves para os olhos
- **Gradientes**: Efeitos visuais modernos
- **AnimaÃ§Ãµes**: TransiÃ§Ãµes suaves e responsivas
- **Tipografia**: Fonte Inter para melhor legibilidade

### Componentes
- **Sidebar**: NavegaÃ§Ã£o organizada por categorias
- **Chat Interface**: Interface moderna de conversaÃ§Ã£o
- **Form Controls**: Controles intuitivos para parÃ¢metros
- **Toast Notifications**: Feedback nÃ£o-intrusivo
- **Loading States**: Indicadores visuais de processamento

### Responsividade
- **Desktop**: Layout otimizado para telas grandes
- **Tablet**: AdaptaÃ§Ã£o para telas mÃ©dias
- **Mobile**: Interface touch-friendly

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente
```bash
# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# API
API_HOST=127.0.0.1
API_PORT=8000
DEBUG=True
```

### Modelos Suportados
- `llama2` (recomendado)
- `mistral`
- `codellama`
- `llama2:7b`
- `llama2:13b`
- `llama2:70b`

## ğŸš€ PrÃ³ximos Passos

1. **Teste o Frontend**: Acesse http://127.0.0.1:8000
2. **Experimente as Funcionalidades**: Use todas as abas disponÃ­veis
3. **Personalize**: Modifique cores e estilos no CSS
4. **Adicione Novas Features**: Implemente novas chains ou funcionalidades
5. **Deploy**: Configure para produÃ§Ã£o

## ğŸ“ LicenÃ§a

MIT License - veja o arquivo LICENSE para detalhes.

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:
- Reportar bugs
- Sugerir novas funcionalidades
- Enviar pull requests
- Melhorar a documentaÃ§Ã£o

---

**Desenvolvido com â¤ï¸ para demonstrar o poder do Ollama + LangChain**
